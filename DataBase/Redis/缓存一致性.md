## 如何保证缓存与数据库双写时的数据一致性?

**先写数据库再删除缓存**

写库的线程宕机了，没有删除掉缓存，导致数据一致性 问题，缓存是旧的。

**删除了缓存再写数据库**

删除了缓存还没来得及，另外一个线程就来读取，发现缓存为空，则会取数据库读取旧的数据写道缓存，此时缓存时脏数据。

**延时双删+ 缓存过期** 

删除数据库，写数据库，休眠，再次删除数据库

我觉得这种方案平白无故的增加了业务接口的执行时间，还会导致再超时时间内缓存有可能依然不是最新的。

**异步更新缓存**

利用`MySQL binlog`增量关联订阅消费+消息队列+增量数据更新到 `redis`。

1.读操作全部在redis。

2.写mysql,增删改全部操作在mySQL.

3.更新redis,mysql的数据操作binlog,来更新redis。

**redis更新**

读取binlog后分析，利用消息队列推送更新redis的缓存数据。

这样一旦数据库中产生了新的写入，更新，删除操作，就可以把binlog的相关消息推送到redis，redis根据消息更新。

听说已经有了现成的框架了。canal

## Redis分布式寻址算法

**hash算法**

对key计算hash值，然后对节点数取模，找到对应的master节点上。

存在的问题是：一旦某一个master节点宕机，所有亲贵过来，会基于最新的剩余master节点数字去取模，这回导致得到的大量请求不是在缓存上，而时落在了数据库。

**一致性hash＋虚拟节点**

将整个hash值空间组织成一个虚拟的圆环，按照顺时针方向组织，对各个master节点进行hash，确定落在环上的位置。对key进行hash计算，确定在换上的位置，从此位置沿着顺时针行走，遇到的第一个master节点就是key的所在位置。

在一致性hash算法中，如果一个节点挂了，受影响的数据仅仅是此节点到换空间钱下一个节点之间的数据。

此算法在节点太少的时候，容i因为节点分布不均匀造成缓存热点的问题，解决的办法时引入虚拟节点，对一个节点计算多个hash，每个计算节点位置防止一个虚拟节点，这样实现了数据的均与分布，负载均衡。

**redis cluter 的hash slot 算法**

redis cluster有固定的16384个hash slot，对每隔二key计算CRC16值，对吼对16382取模，

可以获取key对应的slot。

每个master持有部分的slot，增加一个master，九讲其他maaster的hash slot分配一点出来给他。删除一个，就把他持有的slot分配给其他的master。这样就算宕机，其他节点不受影响。因为请求先定位slot，再根据slot找到机器。